# ConfiguraÃ§Ã£o e Uso do Sistema com LLM

Este documento explica como configurar e testar o **Banco Ãgil** com integraÃ§Ã£o LLM completa usando LangGraph + Groq API.

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- Conta na Groq Cloud (gratuita)
- DependÃªncias instaladas (`pip install -r requirements.txt`)

## ğŸ”‘ Passo 1: Obter API Key do Groq

1. Acesse [https://console.groq.com](https://console.groq.com)
2. FaÃ§a login ou crie uma conta gratuita
3. Navegue atÃ© **API Keys**
4. Clique em **Create API Key**
5. Copie a chave gerada (ela comeÃ§a com `gsk_...`)

## âš™ï¸ Passo 2: Configurar API Key

### OpÃ§Ã£o A: Arquivo .env (Recomendado)

1. Abra o arquivo `.env` na raiz do projeto
2. Adicione sua chave:
   ```
   GROQ_API_KEY=gsk_sua_chave_aqui
   ```
3. Salve o arquivo

### OpÃ§Ã£o B: VariÃ¡vel de Ambiente

**Windows (PowerShell):**
```powershell
$env:GROQ_API_KEY="gsk_sua_chave_aqui"
```

**Linux/Mac:**
```bash
export GROQ_API_KEY="gsk_sua_chave_aqui"
```

## ğŸ§ª Passo 3: Testar a IntegraÃ§Ã£o

### Teste 1: Orquestrador LangGraph

```bash
python banco_agil_langgraph.py
```

**Resultado esperado:**
- Sistema inicializa sem erros
- LLM responde com saudaÃ§Ã£o inicial
- Teste de conversaÃ§Ã£o Ã© executado

### Teste 2: Agentes Individuais

#### Agente de Triagem:
```bash
python agents/triagem_agent_llm.py
```

#### Agente de CrÃ©dito:
```bash
python agents/credito_agent_llm.py
```

#### Agente de Entrevista:
```bash
python agents/entrevista_credito_agent_llm.py
```

#### Agente de CÃ¢mbio:
```bash
python agents/cambio_agent_llm.py
```

### Teste 3: Interface Web com Streamlit

```bash
streamlit run app_llm.py
```

Acesse `http://localhost:8501` no navegador.

## ğŸ­ Fluxo de ConversaÃ§Ã£o Completo

### Exemplo de Teste Ponta a Ponta:

1. **SaudaÃ§Ã£o:**
   - UsuÃ¡rio: "OlÃ¡!"
   - Sistema: SaudaÃ§Ã£o + solicitaÃ§Ã£o de CPF

2. **AutenticaÃ§Ã£o:**
   - UsuÃ¡rio: "12345678901"
   - Sistema: Solicita data de nascimento
   - UsuÃ¡rio: "1990-05-15"
   - Sistema: Autentica + apresenta menu

3. **Consulta de CrÃ©dito:**
   - UsuÃ¡rio: "Quero aumentar meu limite"
   - Sistema: Informa limite atual
   - UsuÃ¡rio: "Quero R$ 8000"
   - Sistema: Aprova ou rejeita baseado no score

4. **Entrevista (se rejeitado):**
   - Sistema: Oferece entrevista financeira
   - UsuÃ¡rio: "Sim, aceito"
   - Sistema: Faz 5 perguntas estruturadas
   - Sistema: Recalcula score

5. **CÃ¢mbio:**
   - UsuÃ¡rio: "Quanto estÃ¡ o dÃ³lar?"
   - Sistema: Retorna cotaÃ§Ã£o em tempo real

6. **Encerramento:**
   - UsuÃ¡rio: "Encerrar"
   - Sistema: Finaliza atendimento

## ğŸ“Š Dados de Teste

### Cliente Exemplo no Banco de Dados:

```
CPF: 12345678901
Data de Nascimento: 1990-05-15
Nome: JoÃ£o Silva
Limite Atual: R$ 5.000,00
Score: 750
```

## ğŸ”§ Arquitetura do Sistema

### Componentes Principais:

```
banco_agil_langgraph.py          # Orquestrador LangGraph
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base_agent.py            # Classe base com LLM
â”‚   â”œâ”€â”€ triagem_agent_llm.py     # AutenticaÃ§Ã£o
â”‚   â”œâ”€â”€ credito_agent_llm.py     # CrÃ©dito
â”‚   â”œâ”€â”€ entrevista_credito_agent_llm.py  # Entrevista
â”‚   â””â”€â”€ cambio_agent_llm.py      # CÃ¢mbio
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ agent_tools.py           # LangChain Tools
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ agent_prompts.py         # System Prompts
â”œâ”€â”€ state.py                     # Estado compartilhado
â””â”€â”€ llm_config.py                # ConfiguraÃ§Ãµes LLM
```

### Fluxo de Estados (LangGraph):

```
[triagem] â†’ (autenticado?) â†’ [menu]
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                   â†“              â†“            â†“
[crÃ©dito]       [entrevista]      [cÃ¢mbio]    [encerramento]
    â†“                   â†“              â†“            â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â†’ [END]
```

## ğŸ¯ ParÃ¢metros LLM por Agente

| Agente | Modelo | Temperature | Top-P | Max Tokens | CaracterÃ­stica |
|--------|--------|-------------|-------|------------|----------------|
| Triagem | Llama 3.1 70B | 0.3 | 0.9 | 200 | Preciso, protocolar |
| CrÃ©dito | Llama 3.1 70B | 0.4 | 0.85 | 250 | EmpÃ¡tico, claro |
| Entrevista | Llama 3.1 70B | 0.7 | 0.95 | 300 | Natural, conversacional |
| CÃ¢mbio | Llama 3.1 70B | 0.2 | 0.8 | 150 | Factual, conciso |

## âš ï¸ Troubleshooting

### Erro: "GROQ_API_KEY nÃ£o encontrada"
- Verifique se o arquivo `.env` contÃ©m a chave
- Verifique se a chave estÃ¡ no formato `gsk_...`
- Tente reiniciar o terminal

### Erro: "Rate limit exceeded"
- Aguarde 1 minuto e tente novamente
- A tier gratuita do Groq tem limites de requisiÃ§Ãµes

### Erro: "Model not found"
- Verifique se o modelo `llama-3.1-70b-versatile` estÃ¡ disponÃ­vel
- Consulte documentaÃ§Ã£o do Groq para modelos atualizados

### Interface Streamlit nÃ£o carrega:
- Verifique se GROQ_API_KEY estÃ¡ configurada
- Execute `streamlit run app_llm.py` (nÃ£o `app.py`)

## ğŸš€ PrÃ³ximos Passos

ApÃ³s validar que tudo funciona:

1. âœ… **Fase 1 Completa**: LLM Integration
2. â³ **Fase 2**: Refinar prompts baseado em testes
3. â³ **Fase 3**: Adicionar mais ferramentas (histÃ³rico, relatÃ³rios)
4. â³ **Fase 4**: Implementar persistÃªncia de conversaÃ§Ã£o
5. â³ **Fase 5**: Deploy em produÃ§Ã£o

## ğŸ“ Notas Importantes

- **Custo**: Groq oferece tier gratuito generoso
- **LatÃªncia**: Groq Ã© extremamente rÃ¡pido (~200ms por resposta)
- **Privacidade**: Dados de teste sÃ£o fictÃ­cios
- **ProduÃ§Ã£o**: Para produÃ§Ã£o, implemente rate limiting e caching

## ğŸ“š ReferÃªncias

- [Groq Documentation](https://console.groq.com/docs)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangChain Documentation](https://python.langchain.com/)

---

**Desenvolvido para o Desafio TÃ©cnico de Agentes de IA**
